# This workflow will run evaluations on all supported built-in evaluators on sample data set
# for a single AI agent with the default result view (boolean scores only).
#
# Prerequisites:
# - Copy to a new GitHub Actions workflow file in the .github/workflows directory.
# - Update the environment variables for your setup.
# - Create GitHub Wiki for the repository.
#   - See https://docs.github.com/en/communities/documenting-your-project-with-wikis/about-wikis

name: AI Agent Evaluation

# Update for your setup
env:
  data-path: "${{ github.workspace }}/sample/dataset.json"
  agent-ids: "<your-agent-id-1>,<your-agent-id-2>"
  baseline-agent-id: "<your-agent-id-1>"
  evaluation-result-view: "all-scores"

on:
  # trigger manually (via GitHub Actions UI)
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  evaluate:
    name: AI Agent Evaluation
    runs-on: ubuntu-latest

    steps:
      - name: Azure login using Federated Credentials
        uses: azure/login@v2
        with:
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}

      - name: Run evaluation
        uses: microsoft/ai-agent-eval@v1
        with:
          azure-aiproject-connection-string: ${{ vars.AZURE_AIPROJECT_CONNECTION_STRING }}
          deployment-name: ${{ vars.DEPLOYMENT_NAME }}
          api-version: ${{ vars.API_VERSION }}
          data-path: ${{ env.data-path }}
          agent-ids: ${{ env.agent-ids }}
          baseline-agent-id: ${{ env.baseline-agent-id }}
          evaluation-result-view: ${{ env.evaluation-result-view }}
